{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Offset computation \n",
    "This notebook computes the offsets for the time synchronization for all the sensors in the array. The time synchronization procedure is as follows:\n",
    " - We insert a patter in the clock of the event camera, the VNAV, and the FLIR camera\n",
    " - We look for this pattern by looking at the timestamps in local clock\n",
    " - We compute the offset between the beginning of the pattern and the local clock\n",
    " - **We use the end of the pattern as the starting point** This is important so the number of messages is consistent between sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import ha_python_utils.constants as const\n",
    "from  ha_python_utils.bag_reader import BagReader\n",
    "from event_camera_py import Decoder as ECDecoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from event_camera_py import Decoder\n",
    "import copy\n",
    "import yaml\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input bag\n",
    "# Experiments on 08.19\n",
    "# BAG = Path(\"/data/ha_ec_data/2024.08.19.Pennov.Flight.and.Calib/cam.calib.1/raw_bag/ha_ec_2024-08-19-12-52-56_0.mcap\")\n",
    "# BAG = Path(\"/data/ha_ec_data/2024.08.19.Pennov.Flight.and.Calib/cam.calib.2/raw_bag/ha_ec_2024-08-19-12-55-58_0.mcap\")\n",
    "# BAG = Path(\"/data/ha_ec_data/2024.08.19.Pennov.Flight.and.Calib/flight.day.1/raw_bag/ha_ec_2024-08-19-11-43-08_0.mcap\")\n",
    "# BAG = Path(\"/data/ha_ec_data/2024.08.19.Pennov.Flight.and.Calib/flight.day.2/raw_bag/ha_ec_2024-08-19-12-11-57_0.mcap\")\n",
    "# BAG = Path(\"/data/ha_ec_data/2024.08.19.Pennov.Flight.and.Calib/imu.calib.1/raw_bag/ha_ec_2024-08-19-13-00-10_0.mcap\")\n",
    "# BAG = Path(\"/data/ha_ec_data/2024.08.19.Pennov.Flight.and.Calib/imu.calib.2/raw_bag/ha_ec_2024-08-19-13-02-06_0.mcap\")\n",
    "# Experiments on 08.25\n",
    "# BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/imu.calib.1/raw_bag/ha_ec_2024-08-25-16-44-38_0.mcap\")\n",
    "# BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/flight.day.4/raw_bag/ha_ec_2024-08-25-17-35-46_0.mcap\")\n",
    "# BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/imu.calib.2/raw_bag/ha_ec_2024-08-25-16-46-30_0.mcap\")\n",
    "# BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/flight.night.3/raw_bag/ha_ec_2024-08-25-20-12-45_0.mcap\")\n",
    "# BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/flight.day.3/raw_bag/ha_ec_2024-08-25-17-15-12_0.mcap\")\n",
    "# BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/cam.calib.1/raw_bag/ha_ec_2024-08-25-16-38-19_0.mcap\")\n",
    "# BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/flight.day.1/raw_bag/ha_ec_2024-08-25-15-27-17_0.mcap\")\n",
    "# BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/flight.night.1/raw_bag/ha_ec_2024-08-25-19-44-20_0.mcap\")\n",
    "# BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/flight.day.2/raw_bag/ha_ec_2024-08-25-15-58-07_0.mcap\")\n",
    "# BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/cam.calib.2/raw_bag/ha_ec_2024-08-25-16-41-21_0.mcap\")\n",
    "# BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/imu.calib.3/raw_bag/ha_ec_2024-08-25-16-48-34_0.mcap\")\n",
    "# BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/flight.night.2/raw_bag/ha_ec_2024-08-25-19-58-42_0.mcap\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables used all over the file\n",
    "SYNC_YAML = BAG.parents[1] / \"sync_info.yaml\"\n",
    "\n",
    "# Print statistics for the whole bag\n",
    "bag_reader = BagReader(str(BAG), const.ALL_INPUT_TOPICS)\n",
    "bag_reader.print_stats(all_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Computation of offset for FLIR camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bag reader only for FLIR msgs\n",
    "bag_reader = BagReader(str(BAG), const.ALL_FLIR_TOPICS)\n",
    "bag_reader.print_stats()\n",
    "\n",
    "# Get number of channels for the FLIR camera\n",
    "flir_number_raw = bag_reader.get_num_msgs(const.FLIR_TOPIC_RAW)\n",
    "flir_number_info = bag_reader.get_num_msgs(const.FLIR_TOPIC_INFO)\n",
    "flir_number_meta = bag_reader.get_num_msgs(const.FLIR_TOPIC_META)\n",
    "\n",
    "\n",
    "# Number of messages for both channels should be the same\n",
    "try:\n",
    "    assert (flir_number_raw == flir_number_info == flir_number_meta)\n",
    "except AssertionError:\n",
    "    print(f\"The number of messages does not match:\")\n",
    "    print(f\"flir_raw: {flir_number_raw}\")\n",
    "    print(f\"flir_info: {flir_number_info}\")\n",
    "    print(f\"flir_meta: {flir_number_meta}\")\n",
    "\n",
    "num_msgs_flir = flir_number_meta\n",
    "if (num_msgs_flir > const.TRIGGER_FREQ*60):\n",
    "    num_msgs_flir = const.TRIGGER_FREQ*60\n",
    "arr_camtime = np.zeros(num_msgs_flir, dtype=np.uint64)\n",
    "arr_header_times = np.zeros((num_msgs_flir, 2), dtype=np.uint64)\n",
    "\n",
    "# Create a bag reader only for meta msgs\n",
    "bag_reader = BagReader(str(BAG), [const.FLIR_TOPIC_META])\n",
    "for i, (topic, msg, t_rec)  in enumerate(bag_reader.read_all()):\n",
    "    if (i == num_msgs_flir):\n",
    "        break\n",
    "    arr_camtime[i] = msg.camera_time - msg.exposure_time*1000\n",
    "    # Log the header times to synchronize non-clocked sensors\n",
    "    arr_header_times[i] = msg.header.stamp.sec, msg.header.stamp.nanosec\n",
    "    \n",
    "    if (i % 500 == 0):\n",
    "        print(f\"{i} - {i/num_msgs_flir}\")\n",
    "\n",
    "arr_camtime_double = arr_camtime.astype(np.double)/1e9 # In s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sequence times for the camera\n",
    "diff_ts = np.diff(arr_camtime_double-arr_camtime_double[0])\n",
    "p99 = np.percentile(diff_ts, 99)\n",
    "print(1/const.TRIGGER_FREQ, p99)\n",
    "assert np.isclose(1/const.TRIGGER_FREQ, p99, atol=1e-6, rtol=1e-4)\n",
    "\n",
    "# Calculate the indices of the peaks\n",
    "peak_idx = np.where(diff_ts > 2*1/const.TRIGGER_FREQ)[0]\n",
    "assert len(peak_idx) == 4\n",
    "\n",
    "# The peak corresponds to the last sample before and after the silence\n",
    "time_diffs_flir = np.diff(arr_camtime_double[peak_idx])\n",
    "\n",
    "diff_with_golden_flir = time_diffs_flir - const.GOLDEN_DIFFS\n",
    "print(f\"Golden diffs: {const.GOLDEN_DIFFS}\")\n",
    "print(f\"This bag diffs: {time_diffs_flir}\")\n",
    "print(f\"Diff with golden in us: {diff_with_golden_flir*1e6}\")\n",
    "\n",
    "# Timing is good when is less than 10 us\n",
    "assert(np.all(diff_with_golden_flir*1e6<10))\n",
    "\n",
    "# Time offset is the time of the first diff\n",
    "first_sample_flir = peak_idx[3]+1\n",
    "#print(arr_camtime[first_sample_flir] - arr_camtime[first_sample_flir -1])\n",
    "time_offset_flir = arr_camtime[first_sample_flir]\n",
    "print(f\"Time offset FLIR: {time_offset_flir}\")\n",
    "time_offset_ros_stamp = arr_header_times[first_sample_flir]\n",
    "\n",
    "# Print timestamp of the first sample to double check\n",
    "print(f\"Timestamp of first sample: {arr_camtime[first_sample_flir] - time_offset_flir}\") \n",
    "offset_wrt_start_trigger_flir = time_offset_flir -arr_camtime[peak_idx[0]]\n",
    "assert np.isclose(const.GOLDEN_DIFFS_PPS, offset_wrt_start_trigger_flir/1e9)\n",
    "print(f\"Offset of first sample wrt start of trigger sequence: {offset_wrt_start_trigger_flir}\")\n",
    "\n",
    "print(f\"Time offset ROS ts: {time_offset_ros_stamp}\")\n",
    "\n",
    "# Plot the time differencies\n",
    "plt.figure()\n",
    "plt.plot(np.diff(arr_camtime_double))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Computation of offset for VNAV IMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bag reader only for VNAV msgs\n",
    "bag_reader = BagReader(str(BAG), [const.VNAV_TOPIC_COMMON])\n",
    "bag_reader.print_stats()\n",
    "\n",
    "num_msgs = bag_reader.get_num_msgs(const.VNAV_TOPIC_COMMON)\n",
    "# Cap to 60 seconds of data\n",
    "if (num_msgs > 400*60):\n",
    "    num_msgs = 400*60\n",
    "arr_syncincnt = np.zeros(num_msgs, dtype=np.uint32)\n",
    "arr_timesyncin = np.zeros(num_msgs, dtype=np.uint64) #ns\n",
    "arr_timestartup = np.zeros(num_msgs, dtype=np.uint64)\n",
    "arr_timegps = np.zeros(num_msgs, dtype=np.uint64)\n",
    "arr_timegpspps = np.zeros(num_msgs, dtype=np.uint16)\n",
    "\n",
    "for i, (topic, msg, t_rec)  in enumerate(bag_reader.read_all()):\n",
    "    if (i == num_msgs):\n",
    "        break\n",
    "\n",
    "    arr_syncincnt[i] = msg.syncincnt\n",
    "    arr_timesyncin[i] = msg.timesyncin\n",
    "    arr_timestartup[i] = msg.timestartup\n",
    "    arr_timegps[i] = msg.timegps\n",
    "    arr_timegpspps[i] = msg.timegpspps\n",
    "    if (i % 2500 == 0):\n",
    "        print(f\"{i} - {i/num_msgs}\")\n",
    "\n",
    "arr_timesyncin_double = arr_timesyncin.astype(np.double)/1e9 #us\n",
    "arr_timestartup_double = arr_timestartup.astype(np.double)/1e9 #us\n",
    "# General plot of the syncincounter\n",
    "#plt.figure()\n",
    "#plt.plot(arr_timesyncin/5e3)\n",
    "#plt.plot(arr_syncincnt)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The VN is running at 400 Hz, and the sync pulse happens every 50 Hz. This means that there are \n",
    "# 8 samples in which syncincnt does not increase.\n",
    "# It also means that the maximum timesyncin difference is 1/50 if we have a constant set of pulses\n",
    "\n",
    "# Find the samples that have more than 1/50 for arr_timesyncin\n",
    "greater_than_trigger_period = np.where(arr_timesyncin_double > 1/const.TRIGGER_FREQ)[0]\n",
    "\n",
    "# Find when we have a discontinuity indicating gaps. The +1 is because the we are detecting the last stable sample of a group\n",
    "gaps = np.where(np.diff(greater_than_trigger_period) > 1)[0] + 1\n",
    "\n",
    "# Also add the first one \n",
    "gaps_idx = np.concatenate((np.array([greater_than_trigger_period[0]]), greater_than_trigger_period[gaps]))\n",
    "\n",
    "# gaps_idx correspond to 8 samples after the trigger happened. Correct this offset\n",
    "gaps_idx -= 8\n",
    "\n",
    "# Verify that these indices have timesyncin that is less than 1/8 of the period of the trigger\n",
    "assert np.all(arr_timesyncin_double[gaps_idx] < (1/8*1/const.TRIGGER_FREQ))\n",
    "\n",
    "# Get all the sensor times for the gaps\n",
    "time_diffs_vnav = np.diff(arr_timestartup_double[gaps_idx] - arr_timesyncin_double[gaps_idx])\n",
    "diff_with_golden_vnav = time_diffs_vnav - const.GOLDEN_DIFFS\n",
    "print(f\"Golden diffs: {const.GOLDEN_DIFFS}\")\n",
    "print(f\"This bag diffs: {time_diffs_vnav}\")\n",
    "print(f\"Diff with golden in us: {diff_with_golden_vnav*1e6}\")\n",
    "\n",
    "# Timing is good when is less than 10 us\n",
    "assert(np.all(diff_with_golden_vnav*1e6<10))\n",
    "\n",
    "# Get the first sample after 207.0027 ms ~= 82/83\n",
    "if arr_timesyncin[np.max(gaps_idx[3])+82] < arr_timesyncin[np.max(gaps_idx[3])+83]:\n",
    "    first_sample_vnav = np.max(gaps_idx[3]) + 82 \n",
    "else:\n",
    "    first_sample_vnav = np.max(gaps_idx[3]) + 83\n",
    "    \n",
    "# Confirm that the offset is correct\n",
    "assert (arr_syncincnt[first_sample_vnav] - arr_syncincnt[gaps_idx[3]]) == 1\n",
    "assert (arr_syncincnt[first_sample_vnav+1] - arr_syncincnt[first_sample_vnav]) == 0\n",
    "assert (arr_syncincnt[first_sample_vnav-1] - arr_syncincnt[gaps_idx[3]]) == 0\n",
    "\n",
    "# Get time offset\n",
    "time_offset_vnav = arr_timestartup[first_sample_vnav] - arr_timesyncin[first_sample_vnav]\n",
    "print(f\"Time offset: {time_offset_vnav}\")\n",
    "offset_wrt_start_trigger_vnav = arr_timestartup[first_sample_vnav] - arr_timesyncin[first_sample_vnav] - (arr_timestartup[np.min(gaps_idx)] - arr_timesyncin[np.min(gaps_idx)])\n",
    "assert np.isclose(const.GOLDEN_DIFFS_PPS, offset_wrt_start_trigger_vnav/1e9)\n",
    "print(f\"Offset of first sample wrt start of trigger sequence: {offset_wrt_start_trigger_vnav}\")\n",
    "\n",
    "# Timestamp of the first sample\n",
    "print(f\"Timestamp of first sample: {arr_timestartup[first_sample_vnav] - time_offset_vnav}\") \n",
    "print(f\"Timesyncin of first sample: {arr_timesyncin[first_sample_vnav]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "for i, idx in enumerate(gaps_idx):\n",
    "    ax[i//2, i%2].plot(np.arange(idx-1, idx+10), arr_timesyncin[idx-1:idx+10])\n",
    "    ax[i//2, i%2].plot(idx, arr_timesyncin[idx], 'or')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Computation of offset Event Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bag reader only for EC msgs\n",
    "bag_reader = BagReader(str(BAG), [const.EC_TOPIC])\n",
    "bag_reader.print_stats()\n",
    "\n",
    "decoder = ECDecoder()\n",
    "# Use the flir trigger to get the event numbers. These should be roughly the same * 2\n",
    "num_msgs = num_msgs_flir*2\n",
    "triggers_ec = np.zeros(num_msgs, dtype=np.uint64)\n",
    "\n",
    "i = 0\n",
    "for topic, msg, t_rec  in bag_reader.read_all():\n",
    "    decoder.decode(msg)\n",
    "    # cd_events = decoder.get_cd_events()\n",
    "    # print(cd_events)\n",
    "    trig_events = decoder.get_ext_trig_events()\n",
    "    if len(trig_events) > 0 and trig_events[0][0] == 1:\n",
    "        assert len(trig_events) == 1\n",
    "        triggers_ec[i] = trig_events[0][1]\n",
    "        i += 1\n",
    "        if (i == num_msgs):\n",
    "            break\n",
    "\n",
    "triggers_ec_double = triggers_ec.astype(np.double)[:i] / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the offsets for the event camera\n",
    "diffs_ec = np.diff(triggers_ec_double)\n",
    "p99 = np.percentile(diffs_ec, 99)\n",
    "assert np.isclose(1/const.TRIGGER_FREQ, p99, atol=1e-6, rtol=1e-4)\n",
    "\n",
    "# Calculate the indices of the peaks\n",
    "peak_idx = np.where(diffs_ec > 3*1/const.TRIGGER_FREQ)[0]\n",
    "print(peak_idx)\n",
    "\n",
    "# Plot the time differencies\n",
    "plt.figure()\n",
    "plt.plot(np.diff(triggers_ec_double[:1000]))\n",
    "plt.show()\n",
    "assert len(peak_idx) == 4\n",
    "\n",
    "# The peak corresponds to the last sample before and after the silence\n",
    "time_diffs_ec = np.diff(triggers_ec_double[peak_idx])\n",
    "\n",
    "diff_with_golden_ec = time_diffs_ec - const.GOLDEN_DIFFS\n",
    "print(f\"Golden diffs: {const.GOLDEN_DIFFS}\")\n",
    "print(f\"This bag diffs: {time_diffs_ec}\")\n",
    "print(f\"Diff with golden in us: {diff_with_golden_ec*1e6}\")\n",
    "\n",
    "# Timing is good when is less than 10 us\n",
    "assert(np.all(diff_with_golden_ec*1e6<10))\n",
    "\n",
    "# Time offset is the time of the first diff\n",
    "first_sample_ec = peak_idx[3] + 1\n",
    "offset_wrt_start_trigger_ec = triggers_ec[first_sample_ec] -triggers_ec[peak_idx[0]]\n",
    "print(f\"Offset of first sample wrt start of trigger sequence: {offset_wrt_start_trigger_ec}\")\n",
    "assert np.isclose(const.GOLDEN_DIFFS_PPS, offset_wrt_start_trigger_ec/1e6)\n",
    "time_offset_ec_pre_cut = triggers_ec[first_sample_ec]\n",
    "\n",
    "# As we will cut the event stream, we need to get a new timestamp for the offset (post cut)\n",
    "# Read https://github.com/ros-event-camera/event_camera_codecs/?tab=readme-ov-file#event-time-stamps for more information\n",
    "bag_reader = BagReader(str(BAG), [const.EC_TOPIC])\n",
    "decoder = ECDecoder()\n",
    "i = 0\n",
    "for topic, msg, t_rec  in bag_reader.read_all():\n",
    "    decoder.decode(msg)\n",
    "    # cd_events = decoder.get_cd_events()\n",
    "    # print(cd_events)\n",
    "    trig_events = decoder.get_ext_trig_events()\n",
    "    if len(trig_events) > 0 and trig_events[0][0] == 1:\n",
    "        if i < first_sample_ec:\n",
    "            i += 1\n",
    "        else:\n",
    "            assert trig_events[0][1] == time_offset_ec_pre_cut\n",
    "            # Instantiate a new decoder and get the time offset\n",
    "            decoder = ECDecoder()\n",
    "            decoder.decode(msg)\n",
    "            trig_events = decoder.get_ext_trig_events()\n",
    "            time_offset_ec_post_cut = trig_events[0][1]\n",
    "            break\n",
    "\n",
    "print(f\"Time offset pre cut: {time_offset_ec_pre_cut}\")\n",
    "print(f\"Time offset post cut: {time_offset_ec_post_cut}\")\n",
    "\n",
    "# Print timestamp of the first sample to double check\n",
    "# print(f\"Old timestamp of first sample: {triggers_ec[first_sample_ec_old] - time_offset_ec}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Computation of offset for SF000 range sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the timestamp of the first camera message for the time offset\n",
    "time_offset_sf000 = time_offset_ros_stamp[0]*1000000000 + time_offset_ros_stamp[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# Computation of offset for UBLOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bag reader only for UBLOX\n",
    "bag_reader = BagReader(str(BAG), [const.TIM_TM2_TOPIC, const.NAVPVT_TOPIC])\n",
    "bag_reader.print_stats()\n",
    "tim_tm2_number = bag_reader.get_num_msgs(const.TIM_TM2_TOPIC)\n",
    "\n",
    "triggers_ublox_ns = np.zeros(tim_tm2_number, dtype=np.int64)\n",
    "\n",
    "i = 0\n",
    "# navpvt_ublox_nano = np.zeros(bag_reader.get_num_msgs(const.NAVPVT_TOPIC), dtype=np.int64)\n",
    "# navpvt_ublox_ms = np.zeros(bag_reader.get_num_msgs(const.NAVPVT_TOPIC), dtype=np.int64)\n",
    "# j = 0\n",
    "for topic, msg, t_rec  in bag_reader.read_all():\n",
    "    if topic == const.TIM_TM2_TOPIC:\n",
    "        # only count rising edge messages\n",
    "        if msg.rising_edge_count == 0:\n",
    "            continue\n",
    "        # There is a 18 second offset between the TIM_TM2 and the NAVPVT message (GNSS vs UTC time)\n",
    "        triggers_ublox_ns[i] = msg.tow_ms_r*1000000 + msg.tow_sub_ms_r + 18000000000\n",
    "        i+=1\n",
    "        if (i % 50 == 0):\n",
    "            print(f\"{i} - {i/tim_tm2_number}\")\n",
    "        if i == tim_tm2_number:\n",
    "            break\n",
    "    # elif topic == const.NAVPVT_TOPIC:\n",
    "    #     navpvt_ublox_nano[j] =  msg.nano # msg.i_tow*1000000 +\n",
    "    #     navpvt_ublox_ms[j] = msg.i_tow*1000000\n",
    "    #     j+=1\n",
    "\n",
    "# napvt_ublox_ns = navpvt_ublox_ns[:j]\n",
    "triggers_ublox_ns = triggers_ublox_ns[:i]\n",
    "triggers_ublox_double = triggers_ublox_ns/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the period where the gap happens\n",
    "up_idx = np.where(np.diff(triggers_ublox_double) > 1.5)[0][0]\n",
    "first_sample_ublox = up_idx+1\n",
    "\n",
    "# Compare this period with the golden diff\n",
    "offset_wrt_start_trigger_ublox = triggers_ublox_ns[first_sample_ublox] - triggers_ublox_ns[up_idx]\n",
    "assert np.isclose(const.GOLDEN_DIFFS_PPS, offset_wrt_start_trigger_ublox/1e9, atol=1e-6, rtol=1e-4)\n",
    "\n",
    "# Compute time offset\n",
    "time_offset_ublox = triggers_ublox_ns[first_sample_ublox]\n",
    "\n",
    "# Compute drift. Skip first and last sample for better results\n",
    "diff_double = triggers_ublox_double[-1] - triggers_ublox_double[up_idx+1]\n",
    "drift_ns_array = np.diff(triggers_ublox_ns[up_idx+2:]) - 1000000000\n",
    "# filter lost samples\n",
    "drift_ns_array = drift_ns_array[drift_ns_array < 10000000] # 10 ms\n",
    "assert np.abs(np.mean(drift_ns_array)) < 10000 # 10 ppm\n",
    "print(f\"Estimated drift ns - mean: {np.mean(drift_ns_array)} - min: {np.min(drift_ns_array)} - max: {np.max(drift_ns_array)} - std: {np.std(drift_ns_array)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# Analysis of results and write to yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the timings for all the sensors\n",
    "print(\"Timing comparison:\")\n",
    "print(f\"EC: {diff_with_golden_ec*1e6}\")\n",
    "print(f\"FLIR: {diff_with_golden_flir*1e6}\")\n",
    "print(f\"VNAV: {diff_with_golden_vnav*1e6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gap timing comparison:\")\n",
    "print(f\"EC: {offset_wrt_start_trigger_ec*1000}\")\n",
    "print(f\"FLIR: {offset_wrt_start_trigger_flir}\")\n",
    "print(f\"VNAV: {offset_wrt_start_trigger_vnav}\")\n",
    "print(f\"UBLOX: {offset_wrt_start_trigger_ublox}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save into yaml\n",
    "time_offsets = {\"offsets\": {\n",
    "                \"ec\":    {\"time_offset_pre_cut\": int(time_offset_ec_pre_cut), \"time_offset_post_cut\": int(time_offset_ec_post_cut), \"first_sample\": int(first_sample_ec)},\n",
    "                \"flir\":  {\"time_offset\": int(time_offset_flir), \"first_sample\": int(first_sample_flir)},\n",
    "                \"vnav\":  {\"time_offset\": int(time_offset_vnav), \"first_sample\": int(first_sample_vnav)},\n",
    "                \"sf000\": {\"time_offset\": int(time_offset_sf000)},\n",
    "                \"ublox\": {\"time_offset\": int(time_offset_ublox), \"first_sample\": int(first_sample_ublox)}},\n",
    "                \"metadata\": {\n",
    "                    \"date_modified\": str(datetime.datetime.now()),\n",
    "                    \"source_bag\": str(BAG.name)},\n",
    "                \"timing_info\": {\n",
    "                \"ec\":    {\"pps_gap_ns\": int(offset_wrt_start_trigger_ec*1000), \"intervals_ns\": [int(i) for i in diff_with_golden_ec*1e9]},\n",
    "                \"flir\":  {\"pps_gap_ns\": int(offset_wrt_start_trigger_flir), \"intervals_ns\": [int(i) for i in diff_with_golden_flir*1e9]},\n",
    "                \"vnav\":  {\"pps_gap_ns\": int(offset_wrt_start_trigger_vnav), \"intervals_ns\": [int(i) for i in diff_with_golden_vnav*1e9]},\n",
    "                \"ublox\": {\"pps_gap_ns\": int(offset_wrt_start_trigger_ublox)}\n",
    "                },\n",
    "                \"drift_per_s_wrt_gps_ns\": {\"mean\": float(np.mean(drift_ns_array)),\n",
    "                                           \"std\": float(np.std(drift_ns_array)),\n",
    "                                           \"min\": int(np.min(drift_ns_array)),\n",
    "                                           \"max\": int(np.max(drift_ns_array))}\n",
    "               }\n",
    "            \n",
    "with open(SYNC_YAML, \"w\") as file:\n",
    "    yaml.dump(time_offsets, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
