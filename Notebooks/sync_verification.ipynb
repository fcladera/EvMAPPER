{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Bag Synchronizer\n",
    "Reads the input bag in mcap format and generates a new bag with synchronized timestamps for the different messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import ha_python_utils.constants as const\n",
    "from  ha_python_utils.bag_reader import BagReader\n",
    "from rclpy.serialization import serialize_message\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import rosbag2_py\n",
    "from event_camera_py import Decoder\n",
    "import copy\n",
    "import time\n",
    "import collections\n",
    "import cv2\n",
    "import pdb\n",
    "import std_msgs.msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input synchronized bag\n",
    "# SYNCED_BAG = Path(\"/data/ha_ec_data/2024.08.19.Pennov.Flight.and.Calib/cam.calib.1/synchronized/synchronized_0.mcap\")\n",
    "SYNCED_BAG = Path(\"/data/ha_ec_data/2024.08.19.Pennov.Flight.and.Calib/cam.calib.2/synchronized/synchronized_0.mcap\")\n",
    "# SYNCED_BAG = Path(\"/data/ha_ec_data/2024.08.19.Pennov.Flight.and.Calib/flight.day.1/synchronized/synchronized_0.mcap\")\n",
    "# SYNCED_BAG = Path(\"/data/ha_ec_data/2024.08.19.Pennov.Flight.and.Calib/flight.day.2/synchronized/synchronized_0.mcap\")\n",
    "# SYNCED_BAG = Path(\"/data/ha_ec_data/2024.08.19.Pennov.Flight.and.Calib/imu.calib.1/synchronized/synchronized_0.mcap\")\n",
    "# SYNCED_BAG = Path(\"/data/ha_ec_data/2024.08.19.Pennov.Flight.and.Calib/imu.calib.2/synchronized/synchronized_0.mcap\")\n",
    "# SYNCED_BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/cam.calib.1/synchronized/synchronized_0.mcap\")\n",
    "# SYNCED_BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/cam.calib.2/synchronized/synchronized_0.mcap\")\n",
    "# SYNCED_BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/flight.day.1/synchronized/synchronized_0.mcap\")\n",
    "# SYNCED_BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/flight.day.2/synchronized/synchronized_0.mcap\")\n",
    "# SYNCED_BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/flight.day.3/synchronized/synchronized_0.mcap\")\n",
    "# SYNCED_BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/flight.day.4/synchronized/synchronized_0.mcap\")\n",
    "# SYNCED_BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/flight.night.1/synchronized/synchronized_0.mcap\")\n",
    "# SYNCED_BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/flight.night.2/synchronized/synchronized_0.mcap\")\n",
    "# SYNCED_BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/flight.night.3/synchronized/synchronized_0.mcap\")\n",
    "# SYNCED_BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/imu.calib.1/synchronized/synchronized_0.mcap\")\n",
    "# SYNCED_BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/imu.calib.2/synchronized/synchronized_0.mcap\")\n",
    "# SYNCED_BAG = Path(\"/data/ha_ec_data/2024.08.25.Pennov.Flight.and.Calib/imu.calib.3/synchronized/synchronized_0.mcap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate synchronized bag topic number\n",
    "bag_reader = BagReader(SYNCED_BAG, const.ALL_OUTPUT_TOPICS)\n",
    "bag_reader.print_stats(all_topics=True)\n",
    "\n",
    "num_imu_msgs = bag_reader.get_num_msgs(const.OUTPUT_VNAV_IMU_TOPIC)\n",
    "num_flir_msgs = bag_reader.get_num_msgs(const.OUTPUT_FLIR_IMAGE_TOPIC)\n",
    "num_gps_msgs = bag_reader.get_num_msgs(const.OUTPUT_GPS_TOPIC)\n",
    "\n",
    "assert num_imu_msgs > 0 and num_flir_msgs > 0 and num_gps_msgs > 0\n",
    "assert np.abs(num_imu_msgs/400 - num_flir_msgs/50) < (1/50 + 1/400)\n",
    "assert np.abs(num_flir_msgs/50 - num_gps_msgs/5) < (1/50 + 1/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the bag to get timestamps\n",
    "   \n",
    "bag_reader = BagReader(SYNCED_BAG, const.ALL_OUTPUT_TOPICS)\n",
    "\n",
    "msg_info = {i: {\"first_msg\": None, \n",
    "                \"first_bag_ts\": None, \n",
    "                \"last_msg\": None, \n",
    "                \"last_bag_ts\": None,\n",
    "                \"cnt\": 0,\n",
    "                \"bag_timestamps\": np.zeros(bag_reader.get_num_msgs(i), dtype=np.int64)} for i in \\\n",
    "            [const.OUTPUT_GPS_TOPIC, const.OUTPUT_VNAV_IMU_TOPIC, const.OUTPUT_EC_EVENTS_TOPIC, const.OUTPUT_FLIR_IMAGE_TOPIC, const.OUTPUT_EC_TRIGGER_TOPIC, const.OUTPUT_RANGE_TOPIC]}\n",
    "\n",
    "for topic, msg, timestamp in bag_reader.read_all():\n",
    "    if topic not in list(msg_info.keys()):\n",
    "        continue\n",
    "    if msg_info[topic][\"first_msg\"] is None:\n",
    "        msg_info[topic][\"first_msg\"] = msg\n",
    "    msg_info[topic][\"last_msg\"] = msg\n",
    "    msg_info[topic][\"bag_timestamps\"][msg_info[topic][\"cnt\"]] = timestamp\n",
    "    msg_info[topic][\"cnt\"] += 1\n",
    "\n",
    "for topic in msg_info:\n",
    "    msg_info[topic][\"first_bag_ts\"] = msg_info[topic][\"bag_timestamps\"][0]\n",
    "    msg_info[topic][\"last_bag_ts\"] = msg_info[topic][\"bag_timestamps\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the events are synchronized with the decoder\n",
    "decoder = Decoder()\n",
    "bag_reader = BagReader(SYNCED_BAG, [const.OUTPUT_EC_EVENTS_TOPIC, const.OUTPUT_EC_TRIGGER_TOPIC])\n",
    "first_trigger_ts = None\n",
    "for topic, msg, timestamp in bag_reader.read_all():\n",
    "    if topic == const.OUTPUT_EC_EVENTS_TOPIC:\n",
    "        # print(timestamp)\n",
    "        msg_ts = msg.header.stamp\n",
    "        decoder.decode(msg)\n",
    "        # events = decoder.get_cd_events()\n",
    "        trigger = decoder.get_ext_trig_events()\n",
    "        if len(trigger) > 0:\n",
    "            if first_trigger_ts is None:\n",
    "                first_trigger_ts = msg_ts\n",
    "                first_trigger_ts_bag = timestamp\n",
    "            else:\n",
    "                break\n",
    "            break\n",
    "    elif topic == const.OUTPUT_EC_TRIGGER_TOPIC:\n",
    "        trigger_msg_ts = msg.stamp\n",
    "        trigger_msg_ts_bag = timestamp\n",
    "        \n",
    "# Check that the trigger topic and the trigger in the event stream agree\n",
    "assert msg_ts == trigger_msg_ts\n",
    "# Check that the first message is a trigger message\n",
    "assert first_trigger_ts == msg_ts\n",
    "# check that the timestamp and the event stream agree for the event topic\n",
    "assert first_trigger_ts.sec*1000000+first_trigger_ts.nanosec//1000 == trigger[0][1]\n",
    "# check that the timestamp and the event stream agree for the trigger topic\n",
    "assert trigger_msg_ts.sec*1000000+trigger_msg_ts.nanosec//1000 == trigger[0][1]\n",
    "# Check that the bag timestamp is correct for the event topic\n",
    "assert first_trigger_ts.sec*1000000000+first_trigger_ts.nanosec == first_trigger_ts_bag\n",
    "# Check that the bag timestamp is correct for the trigger topic\n",
    "assert trigger_msg_ts.sec*1000000000+trigger_msg_ts.nanosec == trigger_msg_ts_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_calculate(bag_timestamps, target_freq):\n",
    "    ''' Estimate frequency statistics given an array of timestamps '''\n",
    "    period = np.diff((bag_timestamps))\n",
    "    target_period = 1/target_freq*1000000000\n",
    "    freq = 1/period*1000000000\n",
    "    # Get the number of lost triggers by looking at the samples that have a period larger than 1 target period\n",
    "    plt.figure()\n",
    "    plt.plot(period)\n",
    "    plt.title(f\"Target freq: {target_freq}\")\n",
    "    lost_triggers = period >= 1.8*target_period\n",
    "    return np.min(freq), np.mean(freq), np.std(freq), np.max(freq), np.count_nonzero(lost_triggers)\n",
    "\n",
    "def get_ts_in_ns(header):\n",
    "    ''' Convert a header msg into nanoseconds '''\n",
    "    assert isinstance(header, std_msgs.msg.Header)\n",
    "    return header.stamp.sec*1000000000 + header.stamp.nanosec\n",
    "\n",
    "# Check the first timestamp\n",
    "try:\n",
    "    # Check that events and regular camera have the same timestamps\n",
    "    assert msg_info[const.OUTPUT_EC_EVENTS_TOPIC][\"first_bag_ts\"] == msg_info[const.OUTPUT_FLIR_IMAGE_TOPIC][\"first_bag_ts\"], \"first_bag_ts for FLIR and EC are not the same\"\n",
    "    assert msg_info[const.OUTPUT_EC_TRIGGER_TOPIC][\"first_bag_ts\"] == msg_info[const.OUTPUT_EC_EVENTS_TOPIC][\"first_bag_ts\"], \"first_bag_ts for EC trigger and topic not the same\"\n",
    "\n",
    "    first_message_diff_gps = msg_info[const.OUTPUT_GPS_TOPIC][\"first_bag_ts\"] - msg_info[const.OUTPUT_EC_EVENTS_TOPIC][\"first_bag_ts\"]\n",
    "    assert first_message_diff_gps > 0 and first_message_diff_gps < const.GPS_T_NS, f\"first_msg_diff_gps is greater than 0.2 seconds: {first_message_diff_gps/1e9}\"\n",
    "    \n",
    "    first_message_diff_imu = msg_info[const.OUTPUT_VNAV_IMU_TOPIC][\"first_bag_ts\"] - msg_info[const.OUTPUT_EC_EVENTS_TOPIC][\"first_bag_ts\"]\n",
    "    assert first_message_diff_imu > 0 and first_message_diff_imu < const.VNAV_T_NS, f\"first_message_diff_imu is greater than 2.5 ms: {first_message_diff_imu/1e6}\"\n",
    "\n",
    "    first_message_diff_range = msg_info[const.OUTPUT_RANGE_TOPIC][\"first_bag_ts\"] - msg_info[const.OUTPUT_EC_EVENTS_TOPIC][\"first_bag_ts\"]\n",
    "    # Be a bit more lenient for the range measurements as the frequency may fluctuate\n",
    "    assert first_message_diff_range > 0 and first_message_diff_range < (const.RANGE_T_NS + 0.002*1e9), f\"first_message_diff_range is greater than 16 ms: {first_message_diff_range/1e6}\"\n",
    "    \n",
    "    # Check that the timestamp in the message agrees with the ROS timestamp\n",
    "    assert get_ts_in_ns(msg_info[const.OUTPUT_FLIR_IMAGE_TOPIC][\"first_msg\"].header) == msg_info[const.OUTPUT_FLIR_IMAGE_TOPIC][\"first_bag_ts\"]\n",
    "    assert get_ts_in_ns(msg_info[const.OUTPUT_VNAV_IMU_TOPIC][\"first_msg\"].header) == msg_info[const.OUTPUT_VNAV_IMU_TOPIC][\"first_bag_ts\"]\n",
    "    assert get_ts_in_ns(msg_info[const.OUTPUT_GPS_TOPIC][\"first_msg\"].header) == msg_info[const.OUTPUT_GPS_TOPIC][\"first_bag_ts\"]\n",
    "    assert get_ts_in_ns(msg_info[const.OUTPUT_RANGE_TOPIC][\"first_msg\"].header) == msg_info[const.OUTPUT_RANGE_TOPIC][\"first_bag_ts\"]\n",
    "    assert get_ts_in_ns(msg_info[const.OUTPUT_EC_TRIGGER_TOPIC][\"first_msg\"]) == msg_info[const.OUTPUT_EC_TRIGGER_TOPIC][\"first_bag_ts\"]\n",
    "    \n",
    "    # Check that the timestamp in the message agrees with the ROS timestamp\n",
    "    assert get_ts_in_ns(msg_info[const.OUTPUT_FLIR_IMAGE_TOPIC][\"last_msg\"].header) == msg_info[const.OUTPUT_FLIR_IMAGE_TOPIC][\"last_bag_ts\"]\n",
    "    assert get_ts_in_ns(msg_info[const.OUTPUT_VNAV_IMU_TOPIC][\"last_msg\"].header) == msg_info[const.OUTPUT_VNAV_IMU_TOPIC][\"last_bag_ts\"]\n",
    "    assert get_ts_in_ns(msg_info[const.OUTPUT_GPS_TOPIC][\"last_msg\"].header) == msg_info[const.OUTPUT_GPS_TOPIC][\"last_bag_ts\"]\n",
    "    assert get_ts_in_ns(msg_info[const.OUTPUT_RANGE_TOPIC][\"last_msg\"].header) == msg_info[const.OUTPUT_RANGE_TOPIC][\"last_bag_ts\"]\n",
    "    assert get_ts_in_ns(msg_info[const.OUTPUT_EC_TRIGGER_TOPIC][\"last_msg\"]) == msg_info[const.OUTPUT_EC_TRIGGER_TOPIC][\"last_bag_ts\"]\n",
    "    \n",
    "    # Check that the last message is within 0.5 s of the bag duration (all msgs are there)\n",
    "    for i in msg_info:\n",
    "        time_diff = np.abs(msg_info[i][\"last_bag_ts\"] -msg_info[i][\"first_bag_ts\"] - bag_reader.get_duration())/1e9\n",
    "        assert time_diff < 1, f\"{i} difference between first and last message is greater than 1 second: {time_diff}\" \n",
    "\n",
    "    #  Check rates for all sensors and number of lost triggers\n",
    "    topic_rates = {const.OUTPUT_FLIR_IMAGE_TOPIC: const.FLIR_FREQ,\n",
    "                   const.OUTPUT_VNAV_IMU_TOPIC: const.VNAV_FREQ,\n",
    "                   const.OUTPUT_GPS_TOPIC: const.GPS_FREQ,\n",
    "                   const.OUTPUT_RANGE_TOPIC: const.RANGE_FREQ,\n",
    "                   const.OUTPUT_EC_TRIGGER_TOPIC: const.EC_TRIGGER_FREQ,}\n",
    "    any_errors = False\n",
    "    for topic in topic_rates:\n",
    "        target_freq = topic_rates[topic]\n",
    "        fmin, fmean, fstd, fmax, lost_triggers = freq_calculate(msg_info[topic][\"bag_timestamps\"], target_freq)\n",
    "        # print(fmin, fmean, fstd, fmax, lost_triggers)\n",
    "        if lost_triggers:\n",
    "            print(f\"{topic} - {lost_triggers} lost triggers detected\")\n",
    "\n",
    "\n",
    "        if topic == const.OUTPUT_RANGE_TOPIC:\n",
    "            if not np.isclose(target_freq, fmean, rtol=1e-2, atol=1e-4):\n",
    "                print(f\"Error checking avg frequency for {topic}. Target frequency: {target_freq}. Average frequency: {fmean}\")\n",
    "                any_errors = True\n",
    "            if not lost_triggers < 5:\n",
    "                print(f\"More than 5 triggers lost for {topic}\")\n",
    "                any_errors = True\n",
    "        elif topic == const.OUTPUT_EC_TRIGGER_TOPIC:\n",
    "            if not np.isclose(target_freq, fmean, rtol=1e-3, atol=1e-6):\n",
    "                print(f\"Error checking avg frequency for {topic}. Target frequency: {target_freq}. Average frequency: {fmean}\")\n",
    "                any_errors = True\n",
    "            if not lost_triggers < 5:\n",
    "                print(f\"More than 5 triggers lost for {topic}\")\n",
    "                any_errors = True\n",
    "        else:\n",
    "            if not np.isclose(fmean, target_freq):\n",
    "                print(f\"Error checking avg frequency for {topic}. Target frequency: {target_freq}. Average frequency: {fmean}\")\n",
    "                any_errors = True\n",
    "            if not lost_triggers == 0:\n",
    "                print(f\"More than 0 triggers lost for {topic}\")\n",
    "                any_errors = True\n",
    "    assert any_errors == False, \"Errors were detected\"\n",
    "    print(\"ALL CHECKS WERE SUCCESSFUL. YAY!\")\n",
    "\n",
    "except AssertionError as msg:\n",
    "    print(\"Error encountered when verifying bag. Consider deleting the bag.\")\n",
    "    print(msg)\n",
    "    # delete_synced_bag()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
