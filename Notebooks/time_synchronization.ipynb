{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Time Synchronization Tests\n",
    "This notebook tests the time synchronization for all the sensors in the array. The time synchronization procedure is as follows:\n",
    " - We insert a patter in the clock of the event camera, the IMU, and the FLIR camera\n",
    " - We look for this pattern by looking at the timestamps in local clock\n",
    " - We compute the offset between the beginning of the pattern and the local clock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from mcap.reader import make_reader\n",
    "from mcap_ros2.decoder import DecoderFactory, Decoder\n",
    "from event_camera_py import Decoder as ECDecoder\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from event_camera_py import Decoder\n",
    "from bag_reader_ros2 import BagReader\n",
    "import copy\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TimeSynchronizer():\n",
    "#     def __init__(bag, topic, num_msgs):\n",
    "#         self.times = np.zeros(num_msgs)\n",
    "#         with open(bag, \"rb\") as f:\n",
    "#             reader = make_reader(f, decoder_factories=[DecoderFactory()])\n",
    "        \n",
    "#             factory = DecoderFactory()\n",
    "#             decoders = {}\n",
    "            \n",
    "#             i = 0\n",
    "#             for schema, channel, encoded_msg in reader.iter_messages():\n",
    "#                 if channel.id != topic:\n",
    "#                     continue\n",
    "#                 # Create decoder for the channel id if it does not exist\n",
    "#                 if channel.id not in decoders:\n",
    "#                     decoders[channel.id] = factory.decoder_for(channel.message_encoding, schema)\n",
    "#                 # decode message\n",
    "#                 decoder = decoders[channel.id]\n",
    "#                 msg = decoder(encoded_msg.data)\n",
    "        \n",
    "#                 self.times[i] = msg.camera_time\n",
    "#                 if (i % 500 == 0):\n",
    "#                     print(f\"{i} - {i/num_msgs}\")\n",
    "#                 i+=1\n",
    "#                 if (i == num_msgs):\n",
    "#                     break\n",
    "#             ;\n",
    "\n",
    "    \n",
    "\n",
    "#     def synchronize(self.)\n",
    "    \n",
    "\n",
    "#     def find_offset():\n",
    "\n",
    "# class SynchronizeFLIR(TimeSynchronizer):\n",
    "#     def __init__(self, bag=None, topic=None, trigger_freq=None, num_msgs=None):\n",
    "#         self.sensor_type = \"FLIR\"\n",
    "#         # Cap to 60 seconds of data, we expect the trigger to happen at the beginning\n",
    "#         if (num_msgs > trigger_freq*60):\n",
    "#             num_msgs = trigger_freq*60\n",
    "#         super().__init__(bag, topic, num_msgs)\n",
    "        \n",
    "                \n",
    "\n",
    "# class SynchronizerEC(TimeSynchronizer):\n",
    "#     def __init__(self, bag=None, topic=None, trigger_freq=None, num_msgs=None):\n",
    "#         self.sensor_type = \"EC\"\n",
    "#         self.num_msgs = num_msgs\n",
    "#         if num_msgs > 2*\n",
    "#         super().__init__(bag, topic, num_msgs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables used all over the file\n",
    "#BAG=Path(\"/data/high_altitude_test/trigger_test/ha_ec_2024-08-09-11-38-38/ha_ec_2024-08-09-11-38-38_0.mcap\")\n",
    "BAG=Path(\"/data/ha_ec_data/2024.08.19.Pennov.Flight.and.Calib/flights/ha_ec_2024-08-19-11-43-08/ha_ec_2024-08-19-11-43-08_0.mcap\")\n",
    "SYNC_YAML=BAG.parent / \"sync_info.yaml\"\n",
    "TRIGGER_FREQ = 50 # Hz\n",
    "\n",
    "# FLIR-related constants\n",
    "FLIR_TOPIC_RAW = \"/cam_sync/cam0/image_raw\"\n",
    "FLIR_TOPIC_INFO =  \"/cam_sync/cam0/camera_info\"\n",
    "FLIR_TOPIC_META = \"/cam_sync/cam0/meta\"\n",
    "\n",
    "# VNAV-related constants\n",
    "VNAV_TOPIC_COMMON = \"/vectornav/raw/common\"\n",
    "\n",
    "# EC-related constants\n",
    "EC_TOPIC = \"/event_camera/events\"\n",
    "\n",
    "# GPS-related constants\n",
    "TIM_TM2_TOPIC = \"/ublox_raw/timtm2\"\n",
    "\n",
    "# Golden diffs are obtained from the logic analyzer\n",
    "GOLDEN_DIFFS = np.array([724.709386, 1306.995370, 1006.996216])*1e-3 # in s\n",
    "GOLDEN_DIFFS_PPS = 3.245707914 # in s\n",
    "\n",
    "# Get statistics from the bag\n",
    "with open(BAG, \"rb\") as f:\n",
    "    reader = make_reader(f, decoder_factories=[DecoderFactory()])\n",
    "\n",
    "    # Get a dictionnary of the channels\n",
    "    ch = reader.get_summary().channels\n",
    "    topics = {ch[idx].topic:idx for idx in ch}\n",
    "    # pprint(topics)\n",
    "    \n",
    "    # Get channel for FLIR and number of messages\n",
    "    stats = reader.get_summary().statistics\n",
    "\n",
    "print(f\"Statistics for bag {BAG.name}:\")\n",
    "pprint(stats)\n",
    "print(f\"\\nList of topics:\")\n",
    "pprint(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Computation of offset for FLIR camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of channels for the FLIR camera\n",
    "flir_channel_raw = topics[FLIR_TOPIC_RAW]\n",
    "flir_channel_info = topics[FLIR_TOPIC_INFO]\n",
    "flir_channel_meta = topics[FLIR_TOPIC_META]\n",
    "flir_number_raw = stats.channel_message_counts[flir_channel_raw]\n",
    "flir_number_info = stats.channel_message_counts[flir_channel_info]\n",
    "flir_number_meta = stats.channel_message_counts[flir_channel_meta]\n",
    "\n",
    "# Number of messages for both channels should be the same\n",
    "try:\n",
    "    assert (flir_number_raw == flir_number_info == flir_number_meta)\n",
    "except AssertionError:\n",
    "    print(f\"The number of messages does not match:\")\n",
    "    print(f\"flir_raw: {flir_number_raw}\")\n",
    "    print(f\"flir_info: {flir_number_info}\")\n",
    "    print(f\"flir_meta: {flir_number_meta}\")\n",
    "\n",
    "\n",
    "num_msgs = flir_number_meta\n",
    "if (num_msgs > TRIGGER_FREQ*60):\n",
    "    num_msgs = TRIGGER_FREQ*60\n",
    "arr_camtime = np.zeros(num_msgs, dtype=np.uint64)\n",
    "arr_header_times = np.zeros((num_msgs, 2), dtype=np.uint64)\n",
    "\n",
    "# timesyncin_arr = np.zeros(\n",
    "with open(BAG, \"rb\") as f:\n",
    "    reader = make_reader(f, decoder_factories=[DecoderFactory()])\n",
    "\n",
    "    factory = DecoderFactory()\n",
    "    decoders = {}\n",
    "    \n",
    "    i = 0\n",
    "    for schema, channel, encoded_msg in reader.iter_messages():\n",
    "        if channel.id != flir_channel_meta:\n",
    "            continue\n",
    "        # Create decoder for the channel id if it does not exist\n",
    "        if channel.id not in decoders:\n",
    "            decoders[channel.id] = factory.decoder_for(channel.message_encoding, schema)\n",
    " \n",
    "        # decode message\n",
    "        decoder = decoders[channel.id]\n",
    "        msg = decoder(encoded_msg.data)\n",
    "        if i == 0:\n",
    "            pprint(f\"{channel.topic} {schema.name}: {msg}\")\n",
    "            \n",
    "\n",
    "        arr_camtime[i] = msg.camera_time\n",
    "        # Log the header times to synchronize non-clocked sensors\n",
    "        arr_header_times[i] = msg.header.stamp.sec, msg.header.stamp.nanosec\n",
    "        \n",
    "        if (i % 500 == 0):\n",
    "            print(f\"{i} - {i/num_msgs}\")\n",
    "        i+=1\n",
    "        if (i == num_msgs):\n",
    "            break\n",
    "    arr_camtime_double = arr_camtime.astype(np.double)/1e9 # In s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sequence times for the camera\n",
    "diff_ts = np.diff(arr_camtime_double-arr_camtime_double[0])\n",
    "p99 = np.percentile(diff_ts, 99)\n",
    "print(1/TRIGGER_FREQ, p99)\n",
    "assert np.isclose(1/TRIGGER_FREQ, p99, atol=1e-6, rtol=1e-4)\n",
    "\n",
    "# Calculate the indices of the peaks\n",
    "peak_idx = np.where(diff_ts > 2*1/TRIGGER_FREQ)[0]\n",
    "assert len(peak_idx) == 4\n",
    "\n",
    "# The peak corresponds to the last sample before and after the silence\n",
    "time_diffs_flir = np.diff(arr_camtime_double[peak_idx])\n",
    "\n",
    "diff_with_golden_flir = time_diffs_flir - GOLDEN_DIFFS\n",
    "print(f\"Golden diffs: {GOLDEN_DIFFS}\")\n",
    "print(f\"This bag diffs: {time_diffs_flir}\")\n",
    "print(f\"Diff with golden in us: {diff_with_golden_flir*1e6}\")\n",
    "\n",
    "# Timing is good when is less than half a ms\n",
    "assert(np.all(diff_with_golden_flir*1e6<500))\n",
    "\n",
    "# Time offset is the time of the first diff\n",
    "time_offset_flir = arr_camtime[peak_idx[0]]\n",
    "print(f\"Time offset FLIR: {time_offset_flir}\")\n",
    "time_offset_ros_stamp = arr_header_times[peak_idx[0]]\n",
    "\n",
    "# Print timestamp of the first sample to double check\n",
    "print(f\"Timestamp of first sample: {arr_camtime[peak_idx[0]] - time_offset_flir}\") \n",
    "\n",
    "print(f\"Time offset ROS ts: {time_offset_ros_stamp}\")\n",
    "\n",
    "# Plot the time differencies\n",
    "plt.figure()\n",
    "plt.plot(np.diff(arr_camtime_double))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Computation of offset for IMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vnav_channel_common = topics[VNAV_TOPIC_COMMON]\n",
    "num_msgs = stats.channel_message_counts[vnav_channel_common]\n",
    "# Cap to 60 seconds of data\n",
    "if (num_msgs > 400*60):\n",
    "    num_msgs = 400*60\n",
    "print(num_msgs)\n",
    "arr_syncincnt = np.zeros(num_msgs, dtype=np.uint32)\n",
    "arr_timesyncin = np.zeros(num_msgs, dtype=np.uint64) #ns\n",
    "arr_timestartup = np.zeros(num_msgs, dtype=np.uint64)\n",
    "arr_timegps = np.zeros(num_msgs, dtype=np.uint64)\n",
    "arr_timegpspps = np.zeros(num_msgs, dtype=np.uint16)\n",
    "\n",
    "with open(BAG, \"rb\") as f:\n",
    "    reader = make_reader(f, decoder_factories=[DecoderFactory()])\n",
    "\n",
    "    factory = DecoderFactory()\n",
    "    decoders = {}\n",
    "    \n",
    "    i = 0\n",
    "    for schema, channel, encoded_msg in reader.iter_messages():\n",
    "        if channel.id != vnav_channel_common:\n",
    "            continue\n",
    "        # Create decoder for the channel id if it does not exist\n",
    "        if channel.id not in decoders:\n",
    "            decoders[channel.id] = factory.decoder_for(channel.message_encoding, schema)\n",
    "\n",
    "        # decode message\n",
    "        decoder = decoders[channel.id]\n",
    "        msg = decoder(encoded_msg.data)\n",
    "        if i == 0:\n",
    "            print(f\"{channel.topic} {schema.name}: {msg}\")\n",
    "            pass\n",
    "\n",
    "        arr_syncincnt[i] = msg.syncincnt\n",
    "        arr_timesyncin[i] = msg.timesyncin\n",
    "        arr_timestartup[i] = msg.timestartup\n",
    "        arr_timegps[i] = msg.timegps\n",
    "        arr_timegpspps[i] = msg.timegpspps\n",
    "        if (i % 2500 == 0):\n",
    "            print(f\"{i} - {i/num_msgs}\")\n",
    "        i+= 1\n",
    "        if i == num_msgs:\n",
    "            break\n",
    "    arr_timesyncin_double = arr_timesyncin.astype(np.double)/1e9 #us\n",
    "    arr_timestartup_double = arr_timestartup.astype(np.double)/1e9 #us\n",
    "# General plot of the syncincounter\n",
    "#plt.figure()\n",
    "#plt.plot(arr_timesyncin/5e3)\n",
    "#plt.plot(arr_syncincnt)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The VN is running at 400 Hz, and the sync pulse happens every 50 Hz. This means that there are \n",
    "# 8 samples in which syncincnt does not increase.\n",
    "# It also means that the maximum timesyncin difference is 1/50 if we have a constant set of pulses\n",
    "\n",
    "# Find the samples that have more than 1/50 for arr_timesyncin\n",
    "greater_than_trigger_period = np.where(arr_timesyncin_double > 1/TRIGGER_FREQ)[0]\n",
    "\n",
    "# Find when we have a discontinuity indicating gaps. The +1 is because the we are detecting the last stable sample of a group\n",
    "gaps = np.where(np.diff(greater_than_trigger_period) > 1)[0] + 1\n",
    "\n",
    "# Also add the first one \n",
    "gaps_idx = np.concatenate((np.array([greater_than_trigger_period[0]]), greater_than_trigger_period[gaps]))\n",
    "\n",
    "# gaps_idx correspond to 8 samples after the trigger happened. Correct this offset\n",
    "gaps_idx -= 8\n",
    "\n",
    "# Verify that these indices have timesyncin that is less than 1/8 of the period of the trigger\n",
    "# print(arr_timesyncin[gaps_idx])\n",
    "assert np.all(arr_timesyncin_double[gaps_idx] < (1/8*1/TRIGGER_FREQ))\n",
    "\n",
    "# Get all the sensor times for the gaps\n",
    "time_diffs_imu = np.diff(arr_timestartup_double[gaps_idx] - arr_timesyncin_double[gaps_idx])\n",
    "diff_with_golden_imu = time_diffs_imu - GOLDEN_DIFFS\n",
    "print(f\"Golden diffs: {GOLDEN_DIFFS}\")\n",
    "print(f\"This bag diffs: {time_diffs_imu}\")\n",
    "print(f\"Diff with golden in us: {diff_with_golden_imu*1e6}\")\n",
    "\n",
    "# Get the first sample\n",
    "first_sample_idx = gaps_idx[0]\n",
    "\n",
    "# Get time offset\n",
    "time_offset_imu = arr_timestartup[first_sample_idx] - arr_timesyncin[first_sample_idx]\n",
    "print(f\"Time offset: {time_offset_imu}\")\n",
    "\n",
    "# Timestamp of the first sample\n",
    "print(f\"Timestamp of first sample: {arr_timestartup[first_sample_idx] - time_offset_imu}\") \n",
    "print(f\"timesyncin of first sample: {arr_timesyncin[first_sample_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "for i, idx in enumerate(gaps_idx):\n",
    "    ax[i//2, i%2].plot(np.arange(idx-1, idx+10), arr_timesyncin[idx-1:idx+10])\n",
    "    ax[i//2, i%2].plot(idx, arr_timesyncin[idx], 'or')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Computation of offset Event Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read events using Bernd's code\n",
    "topic = EC_TOPIC\n",
    "bag = BagReader(BAG, topic)\n",
    "decoder = ECDecoder()\n",
    "# Use the flir trigger to get the event numbers. These should be roughly the same * 2\n",
    "num_msgs = stats.channel_message_counts[flir_channel_meta]*2\n",
    "\n",
    "if (num_msgs > 2*TRIGGER_FREQ*60):\n",
    "    num_msgs = 2*TRIGGER_FREQ*60\n",
    "\n",
    "triggers_ec = np.zeros(num_msgs, dtype=np.uint64)\n",
    "\n",
    "i = 0\n",
    "while bag.has_next():\n",
    "    topic, msg, t_rec = bag.read_next()\n",
    "    decoder.decode(msg)\n",
    "    # cd_events = decoder.get_cd_events()\n",
    "    # print(cd_events)\n",
    "    trig_events = decoder.get_ext_trig_events()\n",
    "    if len(trig_events) > 0 and trig_events[0][0] == 1:\n",
    "        assert len(trig_events) == 1\n",
    "        if i == 0:\n",
    "            print(trig_events)\n",
    "        triggers_ec[i] = trig_events[0][1]\n",
    "        i += 1\n",
    "        # We hope the sequence is at the beginning\n",
    "        if i >= num_msgs:\n",
    "            break\n",
    "triggers_ec_double = triggers_ec.astype(np.double)[:i] / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the offsets for the event camera\n",
    "diffs_ec = np.diff(triggers_ec_double)\n",
    "p99 = np.percentile(diffs_ec, 99)\n",
    "assert np.isclose(1/TRIGGER_FREQ, p99, atol=1e-6, rtol=1e-4)\n",
    "\n",
    "# Calculate the indices of the peaks\n",
    "peak_idx = np.where(diffs_ec > 3*1/TRIGGER_FREQ)[0]\n",
    "print(peak_idx)\n",
    "\n",
    "# Plot the time differencies\n",
    "plt.figure()\n",
    "plt.plot(np.diff(triggers_ec_double[:1000]))\n",
    "plt.show()\n",
    "assert len(peak_idx) == 4\n",
    "\n",
    "# The peak corresponds to the last sample before and after the silence\n",
    "time_diffs_ec = np.diff(triggers_ec_double[peak_idx])\n",
    "\n",
    "diff_with_golden_ec = time_diffs_ec - GOLDEN_DIFFS\n",
    "print(f\"Golden diffs: {GOLDEN_DIFFS}\")\n",
    "print(f\"This bag diffs: {time_diffs_ec}\")\n",
    "print(f\"Diff with golden in us: {diff_with_golden_ec*1e6}\")\n",
    "\n",
    "# Timing is good when is less than half a ms\n",
    "assert(np.all(diff_with_golden_ec*1e6<500))\n",
    "\n",
    "# Time offset is the time of the first diff\n",
    "time_offset_ec = triggers_ec[peak_idx[0]]\n",
    "print(f\"Time offset: {time_offset_ec}\")\n",
    "\n",
    "# Print timestamp of the first sample to double check\n",
    "print(f\"Timestamp of first sample: {triggers_ec[peak_idx[0]] - time_offset_ec}\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Computation of offset for range sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the timestamp of the first camera message for the time offset\n",
    "time_offset_range = time_offset_ros_stamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# Computation of offset for GPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tim_tm2_channel = topics[TIM_TM2_TOPIC]\n",
    "tim_tm2_number = stats.channel_message_counts[tim_tm2_channel]\n",
    "# if tim_tm2_number > 100:\n",
    "#    tim_tm2_number = 120 # Cap to the first 60 seconds\n",
    "\n",
    "triggers_gps = np.zeros((tim_tm2_number, 2), dtype=np.uint32)\n",
    "\n",
    "with open(BAG, \"rb\") as f:\n",
    "    reader = make_reader(f, decoder_factories=[DecoderFactory()])\n",
    "\n",
    "    factory = DecoderFactory()\n",
    "    decoders = {}\n",
    "    \n",
    "    i = 0\n",
    "    for schema, channel, encoded_msg in reader.iter_messages():\n",
    "        if channel.id != tim_tm2_channel:\n",
    "            continue\n",
    "        # Create decoder for the channel id if it does not exist\n",
    "        if channel.id not in decoders:\n",
    "            decoders[channel.id] = factory.decoder_for(channel.message_encoding, schema)\n",
    "       \n",
    "        # decode message\n",
    "        decoder = decoders[channel.id]\n",
    "        msg = decoder(encoded_msg.data)\n",
    "        if i == 0:\n",
    "            print(f\"{channel.topic} {schema.name}: {msg}\")\n",
    "            pass\n",
    "\n",
    "        # only count rising edge messages\n",
    "        if msg.rising_edge_count == 0:\n",
    "            continue\n",
    "               \n",
    "        triggers_gps[i] = msg.tow_ms_r, msg.tow_sub_ms_r\n",
    "        # msg.tow_ms_r/1000 + msg.tow_sub_ms_r/1e9\n",
    "        i+=1\n",
    "        if (i % 50 == 0):\n",
    "            print(f\"{i} - {i/tim_tm2_number}\")\n",
    "        if i == tim_tm2_number:\n",
    "            break\n",
    "triggers_gps = triggers_gps[:i]\n",
    "triggers_gps_double = triggers_gps[:, 0].astype(np.double)/1000 + triggers_gps[:, 1].astype(np.double)/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the period where the gap happens\n",
    "up_idx = np.where(np.diff(triggers_gps_double) > 1.5)[0][0]\n",
    "\n",
    "# Compare this period with the golden diff\n",
    "gap_len = triggers_gps_double[up_idx+1] - triggers_gps_double[up_idx]\n",
    "assert np.isclose(GOLDEN_DIFFS_PPS, gap_len, atol=1e-6, rtol=1e-4)\n",
    "\n",
    "# Compute drift\n",
    "diff = triggers_gps_double[-1] - triggers_gps_double[up_idx+1]\n",
    "drift = diff/(np.round(diff))\n",
    "print(f\"Estimated drift: {1-drift}\")\n",
    "time_offset_gps = triggers_gps[up_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "triggers_gps_double[-1]- triggers_gps_double[up_idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "# Analysis of results and write to yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the timings for all the sensors\n",
    "print(\"Timing comparison:\")\n",
    "print(f\"EC: {diff_with_golden_ec*1e6}\")\n",
    "print(f\"FLIR: {diff_with_golden_flir*1e6}\")\n",
    "print(f\"IMU: {diff_with_golden_imu*1e6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the timestamps in the event camera\n",
    "np.min(np.diff(triggers_ec[1000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Time offsets:\")\n",
    "time_offsets = {\"time_offset_ec\": int(time_offset_ec),\n",
    "                \"time_offset_flir\": int(time_offset_flir),\n",
    "                \"time_offset_imu\": int(time_offset_imu),\n",
    "                \"time_offset_range\": [int(i) for i in time_offset_range],\n",
    "                \"time_offset_gps\": [int(i) for i in time_offset_gps]}\n",
    "pprint(time_offsets)\n",
    "with open(SYNC_YAML, \"w\") as file:\n",
    "    yaml.dump(time_offsets, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
